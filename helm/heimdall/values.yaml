# Default values for heimdall DNS server

replicaCount: 3

# Deployment configuration
revisionHistoryLimit: 3  # Number of old ReplicaSets to keep

image:
  repository: ghcr.io/roeej/heimdall
  pullPolicy: Always  # Always pull latest image for continuous deployment
  # Overrides the image tag whose default is the chart appVersion.
  tag: "latest"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  name: ""

# DNS Server Configuration
config:
  # Upstream DNS servers
  upstreamServers:
    - "1.1.1.1:53"
    - "8.8.8.8:53"
    - "8.8.4.4:53"
  
  # DNS server bind address (internal container port)
  bindAddr: "0.0.0.0:1053"
  
  # HTTP metrics/health server bind address
  httpBindAddr: "0.0.0.0:8080"
  
  # Cache configuration
  cache:
    enabled: true
    maxSize: 10000
    defaultTTL: 300
    saveInterval: 300
    filePath: "/cache/heimdall_cache.rkyv"
  
  # Rate limiting
  rateLimiting:
    enabled: false
    queriesPerSecondPerIP: 100
    globalQueriesPerSecond: 10000
  
  # Performance tuning
  workerThreads: 0  # 0 = auto-detect
  blockingThreads: 512
  maxConcurrentQueries: 1000
  
  # Resolver settings
  upstreamTimeout: 2  # seconds (max: 300)
  maxRetries: 3
  enableParallelQueries: true

service:
  type: LoadBalancer
  # DNS ports
  dnsPort: 53
  dnsProtocol: UDP
  dnsTcpPort: 53
  dnsTcpProtocol: TCP
  # HTTP port for metrics/health
  httpPort: 8080
  httpProtocol: TCP
  
  # Optional: specify loadBalancerIP if you want a specific IP
  # loadBalancerIP: ""
  
  # Optional: annotations for cloud provider load balancers
  annotations: {}
    # service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
    # service.beta.kubernetes.io/azure-load-balancer-internal: "true"

resources:
  limits:
    cpu: 1000m
    memory: 512Mi
  requests:
    cpu: 100m
    memory: 128Mi

autoscaling:
  enabled: false
  minReplicas: 3
  maxReplicas: 10
  targetCPUUtilizationPercentage: 80
  targetMemoryUtilizationPercentage: 80

# Pod disruption budget
podDisruptionBudget:
  enabled: true
  minAvailable: 1

# Persistence for cache
persistence:
  enabled: true
  storageClass: ""
  accessMode: ReadWriteOnce
  size: 1Gi
  # Use existingClaim if you have a pre-created PVC
  # existingClaim: ""

podAnnotations: {}

podSecurityContext:
  runAsNonRoot: true
  runAsUser: 65534
  runAsGroup: 65534
  fsGroup: 65534

securityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  capabilities:
    drop:
    - ALL
    add:
    - NET_BIND_SERVICE

nodeSelector: {}

tolerations: []

affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      podAffinityTerm:
        labelSelector:
          matchExpressions:
          - key: app.kubernetes.io/name
            operator: In
            values:
            - heimdall
        topologyKey: kubernetes.io/hostname

# Probes configuration
livenessProbe:
  httpGet:
    path: /health
    port: http
  initialDelaySeconds: 10
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /health
    port: http
  initialDelaySeconds: 5
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3

# Monitoring
metrics:
  enabled: true
  
  # ServiceMonitor for Prometheus Operator
  serviceMonitor:
    enabled: false
    # Namespace where the ServiceMonitor will be created (defaults to release namespace)
    namespace: ""
    # Scrape interval
    interval: 30s
    # Scrape timeout
    scrapeTimeout: 10s
    # Additional labels for ServiceMonitor
    labels: {}
    # Additional relabelings
    relabelings: []
    # Additional metric relabelings
    metricRelabelings: []
  
  # PodMonitor as alternative to ServiceMonitor
  podMonitor:
    enabled: false
    # Namespace where the PodMonitor will be created (defaults to release namespace)
    namespace: ""
    # Scrape interval
    interval: 30s
    # Scrape timeout
    scrapeTimeout: 10s
    # Additional labels for PodMonitor
    labels: {}
    # Additional relabelings
    relabelings: []
    # Additional metric relabelings
    metricRelabelings: []
  
  # PrometheusRule for alerting
  prometheusRule:
    enabled: false
    # Namespace where the PrometheusRule will be created (defaults to release namespace)
    namespace: ""
    # Rule evaluation interval
    interval: 30s
    # Additional labels for PrometheusRule
    labels: {}
    # Alert configurations
    alerts:
      # High query rate alert
      highQueryRate:
        enabled: true
        threshold: 1000  # queries per second
        for: 5m
      # High error rate alert
      highErrorRate:
        enabled: true
        threshold: 0.05  # 5% error rate
        for: 5m
      # Low cache hit rate alert
      lowCacheHitRate:
        enabled: true
        threshold: 0.5  # 50% cache hit rate
        for: 10m
      # High response time alert
      highResponseTime:
        enabled: true
        threshold: 0.5  # 500ms
        for: 5m
      # Upstream failures alert
      upstreamFailures:
        enabled: true
        threshold: 10  # errors per second
        for: 5m
      # Pod availability alert
      podAvailability:
        enabled: true
        threshold: 0.5  # 50% of pods available
        for: 5m
    # Additional custom rules
    additionalRules: []
  
  # Grafana Dashboard
  grafanaDashboard:
    enabled: false
    # Namespace where the dashboard ConfigMap will be created
    namespace: ""
    # Label that Grafana sidecar uses to discover dashboards
    sidecarLabel: "grafana_dashboard"
    # Additional labels for the ConfigMap
    labels: {}
    # Additional annotations for the ConfigMap
    annotations: {}

# Keel automatic update configuration
keel:
  # Keel annotations for automatic image updates
  annotations:
    # Policy: force (always use :latest tag and force pull)
    keel.sh/policy: force
    # Trigger type: poll (default) or push
    keel.sh/trigger: poll
    # Poll schedule (cron expression) - check every 5 minutes
    keel.sh/pollSchedule: "@every 5m"
    # Force update even if tag hasn't changed
    keel.sh/force: "true"
    # Match image tag pattern (for force policy, typically :latest)
    keel.sh/match-tag: "true"

# Environment variables (additional)
env:
  - name: RUST_LOG
    value: "heimdall=info,warn"

# Volume mounts (additional)
volumeMounts: []

# Volumes (additional)
volumes: []

# Redis configuration for distributed caching
redis:
  # Enable Redis deployment
  enabled: true
  
  image:
    repository: redis
    tag: 7-alpine
    pullPolicy: IfNotPresent
  
  # Redis arguments
  args:
    - --appendonly
    - "yes"
    - --save
    - "60 1000"
    - --save
    - "300 100"
    - --save
    - "900 1"
    - --maxmemory
    - "800mb"
    - --maxmemory-policy
    - "allkeys-lru"
  
  # Authentication
  auth:
    enabled: false
    password: ""
    existingSecret: ""
  
  # Resources
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "1Gi"
      cpu: "500m"
  
  # Persistence
  persistence:
    enabled: true
    size: 10Gi
    storageClass: ""
  
  # Security contexts
  podSecurityContext:
    fsGroup: 999
    runAsUser: 999
    runAsNonRoot: true
  
  securityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: false  # Redis needs to write to /data
    capabilities:
      drop:
      - ALL
  
  # Node selection
  nodeSelector: {}
  tolerations: []
  affinity: {}

# Cluster discovery for multi-replica coordination
clusterDiscovery:
  # Enable headless service for pod discovery
  enabled: true